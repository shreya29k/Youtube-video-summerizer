{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMesnXda1tH+CzF0a0pgVB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreya29k/Youtube-video-summerizer/blob/main/summarizeproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UckV00OconNL",
        "outputId": "5e2beb33-cc69-48ae-b0ba-de61ba528c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.7.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install youtube-transcript-api\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "!pip install transformers\n",
        "\n",
        "!pip install nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk # Import the nltk module\n",
        "nltk.download('punkt')\n",
        "\n",
        "!pip install scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # Import TfidfVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub = YouTubeTranscriptApi.get_transcript(\"i6AZdFxTK9I\")\n"
      ],
      "metadata": {
        "id": "i3t7LwIYoxnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subtitle = \" \".join([x['text'] for x in sub])\n",
        "\n",
        "\n",
        "subtitle = subtitle.replace(\"\\n\", \" \")\n",
        "sentences = sent_tokenize(subtitle)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tV_Bt1rfoxlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf = TfidfVectorizer(min_df=1,\n",
        "                         strip_accents='unicode',\n",
        "                         max_features=None,\n",
        "                         lowercase=True,\n",
        "                         token_pattern=r'\\w{1,}',\n",
        "                         ngram_range=(1, 3),\n",
        "                         use_idf=1,\n",
        "                         smooth_idf=1,\n",
        "                         sublinear_tf=1,\n",
        "                         stop_words='english')\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "sentence_vectors = tf_idf.fit_transform(sentences)\n",
        "sent_scores = np.array(sentence_vectors.sum(axis=1)).ravel()\n",
        "\n",
        "N = 3\n",
        "top_n_sentences = [sentences[index] for index in np.argsort(sent_scores, axis=0)[::-1][:N]]\n",
        "\n",
        "# mapping the scored sentences with their indexes as in the subtitle\n",
        "organized_sent = {k:v for v,k in enumerate(sentences)}\n",
        "mapped_sentences = [(sentence, organized_sent[sentence]) for sentence in top_n_sentences]\n",
        "mapped_sentences = sorted(mapped_sentences, key=lambda x: x[1])\n",
        "ordered_sentences = [element[0] for element in mapped_sentences]\n",
        "summary = \" \".join(ordered_sentences)\n"
      ],
      "metadata": {
        "id": "mh4xS1_8qNZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "input_tensor = tokenizer.encode(subtitle, return_tensors=\"pt\", max_length=512)\n",
        "\n",
        "outputs_tensor = model.generate(input_tensor, max_length=160, min_length=120, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "print(tokenizer.decode(outputs_tensor[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqO4CQCDoxeR",
        "outputId": "a7513d3b-2a7c-4091-c58c-578740551131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "</s><s>With over 3 billion devices running java it has helped shape the world as we know it today. The biggest internet company google has a huge percentage of its development in java accenture is using java for most of its clients hardware companies like intel symantec philips thompson are all java users. java is also considered the official language for android game development pubg the latest youth obsession is a cross-platform game that uses java as a sourcing language since 2007 java has remained a de facto standard and is controlled through the java community process java has evolved to become the most popularly used language.</s>\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline('summarization')\n",
        "\n",
        "# Truncate the input to a maximum length that the model can handle\n",
        "max_input_length = 1024  # Adjust this value based on the model's limitations\n",
        "truncated_subtitle = subtitle[:max_input_length]\n",
        "\n",
        "summary = summarizer(truncated_subtitle, max_length=180, min_length=30)\n",
        "print(summary)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4SwlOaZrfRH",
        "outputId": "e8f8915b-57a4-46e9-9606-a07f398d0e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'summary_text': ' The first public implementation of java was java 1.0 in 1995 . Over 3 billion devices are now running java . The language has helped shape the world as we know it today .'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Ia0hBCjoxcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yYp4hQv8oxaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZJP_ahuGoxXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TjTtIPPCoxVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JHsJ4XEhoxTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nd30t04ToxP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BwSpg_YGoxOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u9aA0XfdoxKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "efSFjE0ToxJK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}